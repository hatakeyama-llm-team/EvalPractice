{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/0520orpo’: File exists\n"
     ]
    }
   ],
   "source": [
    "# instruciton datasetの生成\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder=\"data/0520orpo\"\n",
    "\n",
    "#dataフォルダ内をリセット\n",
    "os.system(f\"mkdir {data_folder}\")\n",
    "os.system(f\"rm -rf {data_folder}/*\")\n",
    "\n",
    "\n",
    "ds_dict={}\n",
    "\n",
    "def clean_autogen(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text=text.strip()\n",
    "    return text\n",
    "\n",
    "question_template=\"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n\"\n",
    "answer_template=\"\\n\\n### 応答:\\n\"\n",
    "\n",
    "\n",
    "records=[]\n",
    "\n",
    "# # mixtralで自動生成したQ&A\n",
    "\n",
    "score_threshold=4\n",
    "ng_words=[\n",
    "          #回答を避けるプロンプトの削除\n",
    "          \"申し訳\",\"分からない\",\"分かりません\",\"すみません\",\n",
    "          #図表などへの言及\n",
    "          \"図\",\"表\",\n",
    "          #日本関係の事項はハルシネーションが多いので消す\n",
    "          \"日本\",\"京都\",\"東京\",\"寿司\", \n",
    "          ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "なぜ人工ニューロンはバイアス項を使うのか？重みを使うだけで十分ではないですか？\n",
      "### 応答:\n",
      "バイアスを導入することは、モデルに調整可能な閾値を持たせるために重要です。\n",
      "例えばReLU活性化関数を持つニューロンを考えると、このニューロンが活性化関数の平坦領域で出力するかどうかは、その入力ベクトルのスケール不変条件のみに依存する可能性があります。\n",
      "したがって、バイアスのかかったニューロンの非線型性は、バイアスのかかっていないニューロンよりもさらに広がる可能性があり、バイアスのかかったニューロンは「私の入力のこの組み合わせは3より大きい」というような客観的な基準を学習するが、バイアスのかかっていないニューロンは「私の入力のこの最初の組み合わせはこの2番目の組み合わせより大きい」というような相対的な基準しか学習しない可能性がある。</s><s>\n",
      "### 指示:\n",
      "平易な言葉で説明してもらえますか？人工ニューロンに詳しくない人のために？\n",
      "\n",
      "### 応答:\n",
      "ディープラーニングで使われているような人工ニューロンは、人間の脳の実際のニューロンの振る舞いをシミュレートするためのものです。人工ニューロンは入力を受け取り、処理し、出力を生成する。このシミュレーションでは、入力はニューロンへの接続の強さを表すように重み付けされ、バイアス項は、入力を受けなくても発火するニューロンの傾向を表す。\n",
      "\n",
      "ニューロンを、入力を出力に変換する小さな機械と考えよう。重みを使って入力と出力を接続するだけなら、入力が十分に強ければ出力が得られるだけである。しかし現実の世界では、ニューロンは入力を受けなくても出力を出す傾向がある。そこでバイアスという用語が登場する。これは、入力が弱くても出力をオンにできる小さなスイッチのような働きをする。\n",
      "\n",
      "言い換えれば、バイアス項は、出力が出る前に超えなければならない閾値のような働きをする。バイアス項を使うことで、ニューロンの振る舞いを微調整することができる。バイアス項がなければ、ニューロンは柔軟性を失い、強い入力を受 け取ったときだけ出力を出すように制限されてしまうだろう。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 13100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#マルチターン\n",
    "ds=load_dataset(\"llm-jp/oasst1-21k-ja\",)[\"train\"]\n",
    "\n",
    "records=[]\n",
    "for record in ds:\n",
    "    conversations=record[\"conversations\"]\n",
    "    if len(conversations)!=4:\n",
    "        continue\n",
    "    q=conversations[0][\"value\"]\n",
    "    q+=\"\\n### 応答:\\n\"+conversations[1][\"value\"]+\"</s><s>\\n### 指示:\\n\"+conversations[2][\"value\"]\n",
    "    a=conversations[3][\"value\"]\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    #records.append(text)\n",
    "    d = {\n",
    "        \"question\": q,\n",
    "        \"ref_answer\": a,\n",
    "        \"dataset\": \"llm-jp/oasst1-21k-ja\",\n",
    "        \"prompt\": text,\n",
    "    }\n",
    "    records.append(d)\n",
    "ds_dict[\"multi_turn_oasst\"]=records\n",
    "print(text),len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "Four kids want to convince their parents to let them all play together outside but, since it's pretty late, their parents won't let them since they might wake up or disrupt their neighbors. The kids then decided to write a song, convincing their parents that they'll be quite outside. What song could've they come up with?\n",
      "### 応答:\n",
      "Verse 1:\n",
      "We promise we'll be quiet,\n",
      "We'll play outside without a riot.\n",
      "We'll keep the volume low,\n",
      "And not disturb the neighbors, you know.\n",
      "\n",
      "Chorus:\n",
      "Let us play, let us play,\n",
      "We won't keep the neighbors up all day.\n",
      "We'll have fun and make no noise,\n",
      "We're good kids, we're not like those boys.\n",
      "\n",
      "Verse 2:\n",
      "We won't shout or scream,\n",
      "We'll play nicely like a dream.\n",
      "We'll stay close to the house,\n",
      "And be quiet like a little mouse.\n",
      "\n",
      "Chorus:\n",
      "Let us play, let us play,\n",
      "We won't keep the neighbors up all day.\n",
      "We'll have fun and make no noise,\n",
      "We're good kids, we're not like those boys.\n",
      "\n",
      "Bridge:\n",
      "We'll be outside for just a bit,\n",
      "And then we'll come back in, we promise.\n",
      "We just want to have some fun,\n",
      "Before the day is finally done.\n",
      "\n",
      "Chorus:\n",
      "Let us play, let us play,\n",
      "We won't keep the neighbors up all day.\n",
      "We'll have fun and make no noise,\n",
      "We're good kids, we're not like those boys.\n",
      "\n",
      "Outro:\n",
      "We promise we'll be good,\n",
      "And do all the things we should.\n",
      "Just let us play for a little while,\n",
      "We'll be quiet with a smile.</s><s>\n",
      "### 指示:\n",
      "The parents answer with a kitschy song about how it's better to sleep yet and that the kids can play tomorrow and the day after tomorrow instead.\n",
      "\n",
      "### 応答:\n",
      "You better go to bed. You better go to bed. You better go to be, do what your mother says.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 21560)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#マルチターン oasst 英語\n",
    "ds=load_dataset(\"llm-jp/oasst2-33k-en\",)[\"train\"]\n",
    "\n",
    "records=[]\n",
    "for record in ds:\n",
    "    conversations=record[\"conversations\"]\n",
    "    if len(conversations)!=4:\n",
    "        continue\n",
    "    q=conversations[0][\"content\"]\n",
    "    q+=\"\\n### 応答:\\n\"+conversations[1][\"content\"]+\"</s><s>\\n### 指示:\\n\"+conversations[2][\"content\"]\n",
    "    a=conversations[3][\"content\"]\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "        \"question\": q,\n",
    "        \"ref_answer\": a,\n",
    "        \"dataset\": \"llm-jp/oasst2-33k-en\",\n",
    "        \"prompt\": text,\n",
    "    }\n",
    "    records.append(d)\n",
    "ds_dict[\"multi_turn_oasst_en\"]=records\n",
    "print(text),len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "最近の忙しさの中で、自分が好きなフィットネスクラスに参加することが出来なくなってきました。仕事や家事、子育てのために毎日の時間はいっぱいで、スポーツを続けることが難しくなりました。しかし、健康は大切です。私たちはどのようにしてフィットネスクラスの習慣を取り組むべきでしょうか？\n",
      "### 応答:\n",
      "わかりました。時間が限られている状態でフィットネスクラスに参加するのは難しいですね。しかし、健康のために継続することは大切です。最初に考えられるのは、自分の時間表を調整してフィットネスクラスに参加する時間を確保することです。</s><s>\n",
      "### 指示:\n",
      "具体的にどのように時間表を調整すればいいのですか？\n",
      "\n",
      "### 応答:\n",
      "具体的な方法は、毎日のスケジュールを確認して、フィットネスクラスに参加する時間帯を決定することが重要です。例えば、仕事や家事、子育てのタイミングを調整して、毎週3回はフィットネスクラスに参加する時間帯を確保します。また、スケジュールが変更された場合は、予め代替日を決定しておくのも良い方法です。こうして時間表を調整することで、フィットネスクラスに参加する習慣を取り込むことが出来ます。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 214139)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# マルチターン　自動生成\n",
    "\n",
    "ds=load_dataset(\"kanhatakeyama/AutoMultiTurnByMixtral8x22b\",)[\"train\"]\n",
    "\n",
    "records=[]\n",
    "for record in ds:\n",
    "    q=record[\"q1\"]\n",
    "    q+=\"\\n### 応答:\\n\"+record[\"a1\"]+\"</s><s>\\n### 指示:\\n\"+record[\"q2\"]\n",
    "    a=record[\"a2\"]\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "        \"question\": q,\n",
    "        \"ref_answer\": a,\n",
    "        \"dataset\": \"kanhatakeyama/AutoMultiTurnByMixtral8x22b\",\n",
    "        \"prompt\": text,\n",
    "    }\n",
    "    records.append(d)\n",
    "ds_dict[\"multi_turn_mixtral\"]=records\n",
    "print(text),len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212355it [00:08, 26468.08it/s]\n",
      "53950it [00:01, 27828.80it/s]\n",
      "21899it [00:00, 28039.84it/s]\n",
      "734876it [00:36, 20088.37it/s]\n",
      "17354it [00:00, 20917.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exclude_count=0\n",
    "\n",
    "datasets=[\n",
    "    #load_dataset(\"hatakeyama-llm-team/AutoGeneratedJapaneseQA\",split=\"train\"),\n",
    "\n",
    "    load_dataset(\"hatakeyama-llm-team/AutoGeneratedJapaneseQA\",split=\"train\"),\n",
    "    load_dataset(\"hatakeyama-llm-team/AutoGeneratedJapaneseQA-CC\",split=\"train\"),\n",
    "    load_dataset(\"hatakeyama-llm-team/AutoGeneratedJapaneseQA-other\",split=\"train\"),\n",
    "    load_dataset(\"kanhatakeyama/OrcaJaMixtral8x22b\",split=\"train\"),\n",
    "    load_dataset(\"kanhatakeyama/ChatbotArenaJaMixtral8x22b\",split=\"train\"),\n",
    "\n",
    "]\n",
    "for dataset in datasets:\n",
    "    for original_record in tqdm(iter(dataset)):\n",
    "        q=clean_autogen(original_record[\"question\"])\n",
    "        a=clean_autogen(original_record[\"answer\"])\n",
    "        if q==\"\" or a==\"\":\n",
    "            continue\n",
    "\n",
    "        if \"score\" in original_record:\n",
    "            if original_record[\"score\"] is None:\n",
    "                continue\n",
    "            if int(original_record[\"score\"])<score_threshold:\n",
    "                continue\n",
    "\n",
    "\n",
    "        exclude_flag=False\n",
    "\n",
    "        #回答しないパターンのrecordを除外\n",
    "        for ng_word in ng_words:\n",
    "            if a.find(ng_word)>=0 or q.find(ng_word)>=0:\n",
    "                #print(\"excluded:\",a)\n",
    "                exclude_flag=True\n",
    "                exclude_count+=1\n",
    "                continue\n",
    "\n",
    "        if exclude_flag:\n",
    "            continue\n",
    "        #if len(a)<10:\n",
    "        #    print(\"too short answer\",a)\n",
    "        #    continue\n",
    "\n",
    "        text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "        if a!=\"\":\n",
    "            d = {\n",
    "                \"question\": q,\n",
    "                \"ref_answer\": a,\n",
    "                \"dataset\": original_record[\"database\"],\n",
    "                \"prompt\": text,\n",
    "            }\n",
    "            records.append(d)\n",
    "\n",
    "ds_dict[\"auto_gen_mixtral\"]=records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 6.59k/6.59k [00:00<00:00, 10.9MB/s]\n",
      "Downloading data: 100%|██████████| 14.7M/14.7M [00:02<00:00, 5.93MB/s]\n",
      "Downloading data: 100%|██████████| 15.6M/15.6M [00:01<00:00, 10.4MB/s]\n",
      "Downloading data: 100%|██████████| 14.2M/14.2M [00:01<00:00, 8.41MB/s]\n",
      "Downloading data: 100%|██████████| 14.5M/14.5M [00:01<00:00, 10.5MB/s]\n",
      "Downloading data: 100%|██████████| 12.1M/12.1M [00:00<00:00, 13.1MB/s]\n",
      "Downloading data: 100%|██████████| 12.3M/12.3M [00:01<00:00, 7.42MB/s]\n",
      "Downloading data: 100%|██████████| 10.4M/10.4M [00:01<00:00, 5.73MB/s]\n",
      "Downloading data: 100%|██████████| 10.6M/10.6M [00:01<00:00, 7.73MB/s]\n",
      "Downloading data: 100%|██████████| 8.59M/8.59M [00:00<00:00, 10.7MB/s]\n",
      "Downloading data: 100%|██████████| 8.88M/8.88M [00:00<00:00, 10.1MB/s]\n",
      "Downloading data: 100%|██████████| 5.68M/5.68M [00:00<00:00, 6.49MB/s]\n",
      "Downloading data: 100%|██████████| 7.39M/7.39M [00:00<00:00, 9.71MB/s]\n",
      "Downloading data: 100%|██████████| 5.68M/5.68M [00:00<00:00, 9.73MB/s]\n",
      "Downloading data: 100%|██████████| 6.61M/6.61M [00:00<00:00, 8.60MB/s]\n",
      "Downloading data: 100%|██████████| 3.64M/3.64M [00:00<00:00, 6.88MB/s]\n",
      "Downloading data: 100%|██████████| 4.19M/4.19M [00:00<00:00, 8.18MB/s]\n",
      "Downloading data: 100%|██████████| 1.30M/1.30M [00:00<00:00, 1.96MB/s]\n",
      "Downloading data: 100%|██████████| 326k/326k [00:00<00:00, 607kB/s]\n",
      "Downloading data: 100%|██████████| 1.44M/1.44M [00:01<00:00, 1.16MB/s]\n",
      "Generating v1.0_cleaned split: 100%|██████████| 28861/28861 [00:00<00:00, 115513.07 examples/s]\n",
      "Generating _archive_v1.0 split: 100%|██████████| 30704/30704 [00:00<00:00, 117586.61 examples/s]\n",
      "Generating _archive_v0.9_cleaned split: 100%|██████████| 28352/28352 [00:00<00:00, 119333.74 examples/s]\n",
      "Generating _archive_v0.9 split: 100%|██████████| 28910/28910 [00:00<00:00, 120079.59 examples/s]\n",
      "Generating _archive_v0.8_cleaned split: 100%|██████████| 24606/24606 [00:00<00:00, 121358.59 examples/s]\n",
      "Generating _archive_v0.8 split: 100%|██████████| 25046/25046 [00:00<00:00, 123081.63 examples/s]\n",
      "Generating _archive_v0.7_cleaned split: 100%|██████████| 21592/21592 [00:00<00:00, 124448.67 examples/s]\n",
      "Generating _archive_v0.7 split: 100%|██████████| 22055/22055 [00:00<00:00, 123563.41 examples/s]\n",
      "Generating _archive_v0.6_cleaned split: 100%|██████████| 18333/18333 [00:00<00:00, 125363.44 examples/s]\n",
      "Generating _archive_v0.6 split: 100%|██████████| 18966/18966 [00:00<00:00, 125529.89 examples/s]\n",
      "Generating _archive_v0.5_cleaned split: 100%|██████████| 12725/12725 [00:00<00:00, 132499.49 examples/s]\n",
      "Generating _archive_v0.5 split: 100%|██████████| 16512/16512 [00:00<00:00, 130934.97 examples/s]\n",
      "Generating _archive_v0.4_cleaned split: 100%|██████████| 12725/12725 [00:00<00:00, 131034.35 examples/s]\n",
      "Generating _archive_v0.4 split: 100%|██████████| 15010/15010 [00:00<00:00, 129040.96 examples/s]\n",
      "Generating _archive_v0.3_cleaned split: 100%|██████████| 8664/8664 [00:00<00:00, 134459.08 examples/s]\n",
      "Generating _archive_v0.3 split: 100%|██████████| 10123/10123 [00:00<00:00, 149935.69 examples/s]\n",
      "Generating _archive_v0.2_cleaned split: 100%|██████████| 3488/3488 [00:00<00:00, 168353.29 examples/s]\n",
      "Generating _archive_v0.1 split: 100%|██████████| 1002/1002 [00:00<00:00, 126313.19 examples/s]\n",
      "Generating _archive_v0.2 split: 100%|██████████| 4003/4003 [00:00<00:00, 177070.23 examples/s]\n",
      "Downloading readme: 100%|██████████| 2.46k/2.46k [00:00<00:00, 6.55MB/s]\n",
      "Downloading data: 100%|██████████| 505k/505k [00:00<00:00, 1.23MB/s]\n",
      "Generating train split: 100%|██████████| 507/507 [00:00<00:00, 37961.91 examples/s]\n",
      "100%|██████████| 28861/28861 [00:03<00:00, 8580.89it/s]\n",
      "100%|██████████| 507/507 [00:00<00:00, 18038.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # hachiさんのalpaca + mixtral dataset\n",
    "\n",
    "# %%\n",
    "\n",
    "hachi_datasets={\n",
    "   \"HachiML/Hachi-Alpaca\": load_dataset(\"HachiML/Hachi-Alpaca\",split='v1.0_cleaned'),\n",
    "    \"HachiML/Evol-Alpaca-gen3-500\":load_dataset(\"HachiML/Evol-Alpaca-gen3-500\",split='train'),\n",
    "}\n",
    "\n",
    "# %%\n",
    "records=[]\n",
    "for key,hachi_ds in hachi_datasets.items():\n",
    "    for record in tqdm(hachi_ds):\n",
    "        q=record[\"instruction\"]\n",
    "        if \"input\" in record:\n",
    "            inp=record[\"input\"]\n",
    "        else:\n",
    "            inp=\"\"\n",
    "        if inp!=\"\":\n",
    "            q+=\"\\n\"+inp\n",
    "        a=record[\"output\"]\n",
    "        if q==\"\" or a==\"\":\n",
    "            continue\n",
    "        text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "        d = {\n",
    "                \"question\": q,\n",
    "                \"ref_answer\": a,\n",
    "                \"dataset\": key,\n",
    "                \"prompt\": text,\n",
    "            }\n",
    "        records.append(d)\n",
    "\n",
    "    ds_dict[f\"hachi_{key}\"]=records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'faカップ準決勝に延長戦はありますか',\n",
       " 'ref_answer': 'YES',\n",
       " 'dataset': 'hatakeyama-llm-team/BumpoRikai',\n",
       " 'prompt': '以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\nfaカップ準決勝に延長戦はありますか\\n\\n### 応答:\\nYES'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # Bumpo dataset\n",
    "\n",
    "#文法理解に関するデータセット\n",
    "ds2=load_dataset(\"hatakeyama-llm-team/BumpoRikai\",split=\"train\")\n",
    "# %%\n",
    "records=[]\n",
    "for original_record in iter(ds2):\n",
    "    q=(original_record[\"question\"])\n",
    "    a=(original_record[\"answer\"])\n",
    "    inst=(original_record[\"instruction\"])\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "            \"question\": q,\n",
    "            \"ref_answer\": a,\n",
    "            \"dataset\": \"hatakeyama-llm-team/BumpoRikai\",\n",
    "            \"prompt\": text,\n",
    "        }\n",
    "    records.append(d)\n",
    "ds_dict[\"bumpo_rikai\"]=records\n",
    "records[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#minnade\n",
    "m_ds=load_dataset(\"minnade/chat-daily\",split=\"train\")\n",
    "\n",
    "id_to_content={}\n",
    "for record in m_ds:\n",
    "    id_to_content[record[\"id\"]]=record[\"body\"]\n",
    "\n",
    "questions=[]\n",
    "for record in m_ds:\n",
    "    if record[\"role\"]==\"assistant\":\n",
    "        q=id_to_content[record[\"parent_id\"]]\n",
    "        a=record[\"body\"]\n",
    "        if a is None:\n",
    "            continue\n",
    "        if len(a)<4:\n",
    "            continue\n",
    "        #questions.append((q,a))\n",
    "        text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "        d = {\n",
    "                \"question\": q,\n",
    "                \"ref_answer\": a,\n",
    "                \"dataset\": \"hatakeyama-llm-team/BumpoRikai\",\n",
    "                \"prompt\": text,\n",
    "            }\n",
    "        records.append(d)\n",
    "ds_dict[\"minnade\"]=questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "all_recrds=[]\n",
    "for k,v in ds_dict.items():\n",
    "    all_recrds+=v\n",
    "\n",
    "# %%\n",
    "\n",
    "def write_jsonl(records,\n",
    "    output_path=\"data/all.jsonl\",\n",
    "    n_eval=500,\n",
    "    n_train=10**7,\n",
    "    ):\n",
    "\n",
    "    random.shuffle(records)\n",
    "    df=pd.DataFrame.from_dict(records[:-n_eval][:n_train])\n",
    "    df[\"text\"]=df[\"prompt\"].astype(str)\n",
    "    df=df.drop(\"prompt\",axis=1)\n",
    "    df=df.reset_index()\n",
    "    df.to_parquet(output_path)\n",
    "    \n",
    "    #eval\n",
    "    df=pd.DataFrame.from_dict(records[-n_eval:])\n",
    "    df[\"text\"]=df[\"prompt\"].astype(str)\n",
    "    df=df.drop(\"prompt\",axis=1)\n",
    "    df=df.reset_index()\n",
    "    df.to_parquet(output_path.replace(\".parquet\",\"_eval.parquet\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=10**10\n",
    "#df=write_jsonl(all_recrds,f\"{data_folder}/all_{n_train}.parquet\",n_train=n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ds_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nopenmath_ds=load_dataset(\"kunishou/OpenMathInstruct-1-1.8m-ja\",split=\"train\")\\n\\nrecords=[]\\nfor original_record in iter(openmath_ds):\\n    q=(original_record[\"question_ja\"])\\n    a=(original_record[\"generated_solution_ja\"])\\n    #inst=(original_record[\"instruction\"])\\n    if q==\"\" or a==\"\":\\n        continue\\n    text=f\"{question_template}{q}{answer_template}{a}\"\\n    records.append(text)\\ncode_ds_dict[\"openmathja\"]=records\\nrecords[1]\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#openmathinst 数GB\n",
    "# 思考が硬直化してそうなので、やめる\n",
    "\"\"\"\n",
    "openmath_ds=load_dataset(\"kunishou/OpenMathInstruct-1-1.8m-ja\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(openmath_ds):\n",
    "    q=(original_record[\"question_ja\"])\n",
    "    a=(original_record[\"generated_solution_ja\"])\n",
    "    #inst=(original_record[\"instruction\"])\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    records.append(text)\n",
    "code_ds_dict[\"openmathja\"]=records\n",
    "records[1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 6.95k/6.95k [00:00<00:00, 12.7MB/s]\n",
      "Downloading data: 100%|██████████| 4.55M/4.55M [00:01<00:00, 4.18MB/s]\n",
      "Downloading data: 100%|██████████| 4.58M/4.58M [00:00<00:00, 5.08MB/s]\n",
      "Downloading data: 100%|██████████| 3.69M/3.69M [00:00<00:00, 7.04MB/s]\n",
      "Downloading data: 100%|██████████| 3.75M/3.75M [00:00<00:00, 5.90MB/s]\n",
      "Downloading data: 100%|██████████| 1.52M/1.52M [00:00<00:00, 3.24MB/s]\n",
      "Downloading data: 100%|██████████| 3.25M/3.25M [00:00<00:00, 6.29MB/s]\n",
      "Generating v1.0_cleaned split: 100%|██████████| 10960/10960 [00:00<00:00, 93817.56 examples/s]\n",
      "Generating _archive_v1.0 split: 100%|██████████| 11024/11024 [00:00<00:00, 118456.33 examples/s]\n",
      "Generating _archive_v0.2_cleaned split: 100%|██████████| 9066/9066 [00:00<00:00, 119388.76 examples/s]\n",
      "Generating _archive_v0.2 split: 100%|██████████| 9221/9221 [00:00<00:00, 119774.17 examples/s]\n",
      "Generating _archive_v0.1_cleaned split: 100%|██████████| 3910/3910 [00:00<00:00, 116643.52 examples/s]\n",
      "Generating _archive_v0.1 split: 100%|██████████| 8629/8629 [00:00<00:00, 127036.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': '与えられたリスト内の重複する値を除去するPythonスクリプトを書きなさい。\\n```python\\nnumbers = [1, 2, 2, 3, 4, 4, 5]\\n```',\n",
       " 'ref_answer': '```python\\nunique_numbers = list(set(numbers))\\nprint(unique_numbers)\\n```',\n",
       " 'dataset': 'HachiML/alpaca_jp_python',\n",
       " 'prompt': '以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n与えられたリスト内の重複する値を除去するPythonスクリプトを書きなさい。\\n```python\\nnumbers = [1, 2, 2, 3, 4, 4, 5]\\n```\\n\\n### 応答:\\n```python\\nunique_numbers = list(set(numbers))\\nprint(unique_numbers)\\n```'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code 50k\n",
    "ds=load_dataset(\"HachiML/alpaca_jp_python\",split=\"v1.0_cleaned\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"instruction\"])\n",
    "    a=(original_record[\"output\"])\n",
    "    inp=(original_record[\"input\"])\n",
    "    if inp!=\"\":\n",
    "        q+=\"\\n\"+inp\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "            \"question\": q,\n",
    "            \"ref_answer\": a,\n",
    "            \"dataset\": \"HachiML/alpaca_jp_python\",\n",
    "            \"prompt\": text,\n",
    "        }\n",
    "    records.append(d)\n",
    "code_ds_dict[\"code_hachi\"]=records\n",
    "records[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'pandasでレシート明細データ（df_receipt）から売上年月日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、10件表示せよ。',\n",
       " 'ref_answer': \"import pandas as pd\\n\\ndf_receipt[['sales_ymd', 'customer_id', 'product_cd', 'amount']].head(10)\",\n",
       " 'dataset': 'kunishou/amenokaku-code-instruct',\n",
       " 'prompt': \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\npandasでレシート明細データ（df_receipt）から売上年月日（sales_ymd）、顧客ID（customer_id）、商品コード（product_cd）、売上金額（amount）の順に列を指定し、10件表示せよ。\\n\\n### 応答:\\nimport pandas as pd\\n\\ndf_receipt[['sales_ymd', 'customer_id', 'product_cd', 'amount']].head(10)\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code 5k\n",
    "ds=load_dataset(\"kunishou/amenokaku-code-instruct\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"instruction\"])\n",
    "    a=(original_record[\"output\"])\n",
    "    inp=(original_record[\"input\"])\n",
    "    if inp!=\"\":\n",
    "        q+=\"\\n\"+inp\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "            \"question\": q,\n",
    "            \"ref_answer\": a,\n",
    "            \"dataset\": \"kunishou/amenokaku-code-instruct\",\n",
    "            \"prompt\": text,\n",
    "        }\n",
    "    records.append(d)\n",
    "code_ds_dict[\"amenokaku\"]=records\n",
    "records[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '小王は、20％の薬を含む農薬150kgを、5％の薬を含む溶液に希釈したいと考えています。 何kgの水を加えればよいでしょうか。',\n",
       " 'ref_answer': 'x=150*20%/5%-150 よって答えは 450キログラム',\n",
       " 'dataset': 'saldra/sakura_japanese_dataset',\n",
       " 'prompt': '以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n小王は、20％の薬を含む農薬150kgを、5％の薬を含む溶液に希釈したいと考えています。 何kgの水を加えればよいでしょうか。\\n\\n### 応答:\\nx=150*20%/5%-150 よって答えは 450キログラム'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#算数 0.5k\n",
    "ds=load_dataset(\"saldra/sakura_japanese_dataset\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"instruction\"])\n",
    "    a=(original_record[\"output\"])\n",
    "    inp=(original_record[\"input\"])\n",
    "    if inp!=\"\":\n",
    "        q+=\"\\n\"+inp\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "            \"question\": q,\n",
    "            \"ref_answer\": a,\n",
    "            \"dataset\": \"saldra/sakura_japanese_dataset\",\n",
    "            \"prompt\": text,\n",
    "        }\n",
    "    records.append(d)\n",
    "code_ds_dict[\"sakura\"]=records\n",
    "records[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nds=load_dataset(\"meta-math/MetaMathQA\",split=\"train\")\\n\\nrecords=[]\\nfor original_record in iter(ds):\\n    q=(original_record[\"query\"])\\n    a=(original_record[\"response\"])\\n    if q==\"\" or a==\"\":\\n        continue\\n    text=f\"{question_template}{q}{answer_template}{a}\"\\n    records.append(text)\\ncode_ds_dict[\"meta_math\"]=records\\nrecords[1]\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta math\n",
    "#数学的な基礎力が低く、勉強してもあまり意味がなさそう\n",
    "\"\"\"\n",
    "ds=load_dataset(\"meta-math/MetaMathQA\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"query\"])\n",
    "    a=(original_record[\"response\"])\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    records.append(text)\n",
    "code_ds_dict[\"meta_math\"]=records\n",
    "records[1]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nds=load_dataset(\"microsoft/orca-math-word-problems-200k\",split=\"train\")\\n\\nrecords=[]\\nfor original_record in iter(ds):\\n    q=(original_record[\"question\"])\\n    a=(original_record[\"answer\"])\\n    if q==\"\" or a==\"\":\\n        continue\\n    text=f\"{question_template}{q}{answer_template}{a}\"\\n    records.append(text)\\ncode_ds_dict[\"orca_math\"]=records\\nrecords[1]\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ds=load_dataset(\"microsoft/orca-math-word-problems-200k\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"question\"])\n",
    "    a=(original_record[\"answer\"])\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    records.append(text)\n",
    "code_ds_dict[\"orca_math\"]=records\n",
    "records[1]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Write a function to find the number of distinct states in a given matrix. Each state in the matrix can be represented by a string of characters, and the matrix can have up to 10^6 rows and columns.\\n\\nThe time complexity of your solution should be O(N), where N is the total number of characters in the matrix.\\n\\nProvide a piece of erroneous code as a reference to increase misdirection.\\n\\n# Misdirection code #\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            if col not in states:\\n                count += 1\\n            states.add(col)\\n    return count\\n\\n# Correct code #\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            state = ''.join(col)\\n            if state not in states:\\n                count += 1\\n            states.add(state)\\n    return count\\n\\nmatrix = [['A', 'B', 'C'],\\n          ['A', 'B', 'D'],\\n          ['A', 'B', 'C']]\\nprint(count_distinct_states(matrix))\\n# Output: 4\",\n",
       " 'ref_answer': \"The given problem can be solved by iterating through each cell of the matrix and converting the state of the cell into a string. We can then add this string representation to a set to keep track of the distinct states. Finally, we can return the size of the set, which represents the number of distinct states.\\n\\nHere's the correct code to solve the problem:\\n\\n```python\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            state = ''.join(col)\\n            if state not in states:\\n                count += 1\\n            states.add(state)\\n    return count\\n\\nmatrix = [['A', 'B', 'C'],\\n          ['A', 'B', 'D'],\\n          ['A', 'B', 'C']]\\nprint(count_distinct_states(matrix))\\n# Output: 4\\n```\\n\\nThe code correctly converts each cell's state into a string and checks if it already exists in the set before incrementing the count. This ensures that only distinct states are counted.\\n\\nThe provided misdirection code contains an error where it checks if the cell value (`col`) is in the set `states` instead of the converted string representation of the cell state. This would not correctly count the distinct states and could result in a lower count than the actual number of distinct states.\",\n",
       " 'dataset': 'm-a-p/CodeFeedback-Filtered-Instruction',\n",
       " 'prompt': \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\nWrite a function to find the number of distinct states in a given matrix. Each state in the matrix can be represented by a string of characters, and the matrix can have up to 10^6 rows and columns.\\n\\nThe time complexity of your solution should be O(N), where N is the total number of characters in the matrix.\\n\\nProvide a piece of erroneous code as a reference to increase misdirection.\\n\\n# Misdirection code #\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            if col not in states:\\n                count += 1\\n            states.add(col)\\n    return count\\n\\n# Correct code #\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            state = ''.join(col)\\n            if state not in states:\\n                count += 1\\n            states.add(state)\\n    return count\\n\\nmatrix = [['A', 'B', 'C'],\\n          ['A', 'B', 'D'],\\n          ['A', 'B', 'C']]\\nprint(count_distinct_states(matrix))\\n# Output: 4\\n\\n### 応答:\\nThe given problem can be solved by iterating through each cell of the matrix and converting the state of the cell into a string. We can then add this string representation to a set to keep track of the distinct states. Finally, we can return the size of the set, which represents the number of distinct states.\\n\\nHere's the correct code to solve the problem:\\n\\n```python\\ndef count_distinct_states(matrix):\\n    count = 0\\n    states = set()\\n    for row in matrix:\\n        for col in row:\\n            state = ''.join(col)\\n            if state not in states:\\n                count += 1\\n            states.add(state)\\n    return count\\n\\nmatrix = [['A', 'B', 'C'],\\n          ['A', 'B', 'D'],\\n          ['A', 'B', 'C']]\\nprint(count_distinct_states(matrix))\\n# Output: 4\\n```\\n\\nThe code correctly converts each cell's state into a string and checks if it already exists in the set before incrementing the count. This ensures that only distinct states are counted.\\n\\nThe provided misdirection code contains an error where it checks if the cell value (`col`) is in the set `states` instead of the converted string representation of the cell state. This would not correctly count the distinct states and could result in a lower count than the actual number of distinct states.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#python codes 150k\n",
    "ds=load_dataset(\"m-a-p/CodeFeedback-Filtered-Instruction\",split=\"train\")\n",
    "\n",
    "records=[]\n",
    "for original_record in iter(ds):\n",
    "    q=(original_record[\"query\"])\n",
    "    a=(original_record[\"answer\"])\n",
    "    if q==\"\" or a==\"\":\n",
    "        continue\n",
    "    text=f\"{question_template}{q}{answer_template}{a}\"\n",
    "    d = {\n",
    "            \"question\": q,\n",
    "            \"ref_answer\": a,\n",
    "            \"dataset\": \"m-a-p/CodeFeedback-Filtered-Instruction\",\n",
    "            \"prompt\": text,\n",
    "        }\n",
    "    records.append(d)\n",
    "code_ds_dict[\"codefeedback\"]=records\n",
    "records[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173360"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "all_code_records=[]\n",
    "for k,v in code_ds_dict.items():\n",
    "    all_code_records+=v\n",
    "len(all_code_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_train=10**10\n",
    "_=write_jsonl(all_recrds+all_code_records,f\"{data_folder}/code_all_{n_train}.parquet\",n_train=n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898089"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_recrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
