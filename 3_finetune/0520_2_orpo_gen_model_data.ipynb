{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatakeyama/miniconda3/envs/llmeval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-20 13:59:59,229\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import SamplingParams\n",
    "import string\n",
    "from vllm import LLM\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "model_name = \"hatakeyama-llm-team/tanuki_inst_0515test\"\n",
    "n_batch = 1000\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('jobid', type=int, help='Job ID')\n",
    "parser.add_argument('model_name', type=str, help='model name')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Parsed arguments:\")\n",
    "print(args)\n",
    "\n",
    "job_id = args.jobid\n",
    "model_name = args.model_name\n",
    "\n",
    "print(f\"Job ID: {job_id}\")\n",
    "print(f\"Model Name: {model_name}\")\n",
    "\n",
    "print(job_id,model_name)\n",
    "\n",
    "#job_id=1\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{job_id}\"\n",
    "n_jobs=8\n",
    "current_time_no_symbols = datetime.now().strftime(\n",
    "    \"%Y-%m-%d %H:%M:%S\").replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"\")\n",
    "out_path = f\"data/0520orpo_model/job_{job_id}_{current_time_no_symbols}.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"data/0520orpo/code_all_10000000000.parquet\")\n",
    "master_records=df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init models...\n",
      "INFO 05-20 14:00:24 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='/home/hatakeyama/python/EvalPractice/model/0519mult_c_-home-hatakeyama-python-llm-models-hf-epoch2_step12697_inst_0519mult_c-code_all_10000000000-parquet_lr_5e-5_bf16', speculative_config=None, tokenizer='/home/hatakeyama/python/EvalPractice/model/0519mult_c_-home-hatakeyama-python-llm-models-hf-epoch2_step12697_inst_0519mult_c-code_all_10000000000-parquet_lr_5e-5_bf16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/home/hatakeyama/python/EvalPractice/model/0519mult_c_-home-hatakeyama-python-llm-models-hf-epoch2_step12697_inst_0519mult_c-code_all_10000000000-parquet_lr_5e-5_bf16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-20 14:00:25 utils.py:660] Found nccl from library /home/hatakeyama/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-20 14:00:26 selector.py:27] Using FlashAttention-2 backend.\n",
      "INFO 05-20 14:00:30 model_runner.py:175] Loading model weights took 13.9932 GB\n",
      "INFO 05-20 14:00:32 gpu_executor.py:114] # GPU blocks: 28751, # CPU blocks: 2048\n",
      "INFO 05-20 14:00:34 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-20 14:00:34 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-20 14:00:41 model_runner.py:1017] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "print(\"init models...\")\n",
    "llm = LLM(model=model_name, trust_remote_code=True)\n",
    "\n",
    "# %%\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25886 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "  0%|          | 0/25886 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer_template=\"\\n\\n### 応答:\\n\"\n",
    "\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "random.seed(42)\n",
    "random.shuffle(master_records)\n",
    "\n",
    "#jobで分割\n",
    "job_size=int(len(master_records)/n_jobs)\n",
    "records=master_records[job_id*job_size:(job_id+1)*job_size]\n",
    "\n",
    "cnt = 0\n",
    "for i in tqdm(range(int(len(records)/n_batch))):\n",
    "    # プロンプトの準備\n",
    "    sampled_records = records[cnt*n_batch:(cnt+1)*n_batch]\n",
    "\n",
    "    prompts = []\n",
    "    for record in sampled_records:\n",
    "        q=record[\"text\"]\n",
    "        q=q[:q.rfind(answer_template)+len(answer_template)]\n",
    "        prompts.append(tokenizer.encode(q)[:-1])\n",
    "\n",
    "    # 推論の実行\n",
    "    outputs = llm.generate(\n",
    "        # prompts,\n",
    "        prompt_token_ids=prompts,\n",
    "        sampling_params=SamplingParams(\n",
    "            temperature=0.1,\n",
    "            max_tokens=512,\n",
    "        )\n",
    "    )\n",
    "    for i, output in enumerate(outputs):\n",
    "        sampled_records[i][\"model_answer\"] = output.outputs[0].text\n",
    "\n",
    "    with open(out_path, \"a\") as f:\n",
    "        for record in sampled_records:\n",
    "            #record.pop(\"text\")\n",
    "            f.write(json.dumps(record, ensure_ascii=False))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts),len(sampled_records),len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=39, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 4242, 10523, 810, 7259, 6476, 293, 296, 3955, 312, 272, 39181, 7314, 322, 8692, 62115, 312, 355, 272, 34888, 25252, 28124, 380, 10798, 1249, 980, 519, 3955, 312, 272, 62115, 272, 16116, 340, 296, 16373, 312, 355, 1638, 4545, 627, 6679, 1619, 355, 13169, 4206, 287, 21015, 377, 766, 340, 642, 15024, 347, 355, 4160, 627, 11351, 12863, 287, 627, 28793, 369, 272, 5777, 355, 7767, 13291, 12762, 436, 5632, 26633, 347, 296, 3022, 627, 355, 2521, 7735, 8135, 284, 8, 8, 34642, 17365, 419, 340, 50855, 812, 6976, 477, 909, 5826, 429, 272, 43944, 322, 272, 53183, 355, 14912, 7607, 9768, 284, 519, 3842, 312, 1267, 272, 62115, 372, 6601, 62115, 6976, 419, 849, 21282, 284, 2483, 2173, 287, 766, 419, 8773, 340, 6543, 477, 355, 14912, 7607, 9768, 909, 642, 25384, 7915, 1619, 355, 7450, 9528, 287, 322, 760, 7450, 909, 642, 9878, 429, 272, 53183, 506, 340, 25749, 296, 6040, 9768, 4545, 284, 8, 8, 4242, 8515, 24353, 7450, 3301, 642, 520, 36000, 520, 4520, 284, 8, 8, 14991, 6995, 287, 3409, 296, 3783, 3066, 293, 327, 8, 8, 33876, 272, 279, 327, 8, 27190, 18589, 27750, 327, 10067, 406, 774, 283, 287, 279, 287, 299, 730, 8, 45471, 24881, 327, 774, 283, 287, 279, 287, 299, 730, 8, 8, 33876, 272, 283, 327, 8, 27190, 18589, 27750, 327, 10067, 406, 6470, 8, 45471, 24881, 327, 6470, 8, 8, 37423, 9563, 296, 3783, 272, 16690, 327, 8, 4242, 9768, 453, 293, 10162, 8388, 10998, 293, 2979, 296, 3791, 6085, 674, 280, 287, 272, 279, 280, 311, 730, 20442, 8, 8, 4925, 280, 3954, 20207, 907, 551, 33298, 284, 7348, 3954, 20207, 907, 551, 272, 279, 280, 311, 4925, 8, 4242, 6043, 9768, 419, 520, 20929, 369, 340, 642, 355, 14912, 7607, 9768, 284, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='This problem can be solved using a recursive approach. The idea is to convert the binary search tree into a string and then decode it back to the binary search tree.\\n\\nHere is a Python solution:\\n\\n```python\\nclass Node:\\n    def __init__(self, x):\\n        self.val = x\\n        self.left = None\\n        self.right = None\\n\\ndef serialize(root):\\n    if root is None:\\n        return None\\n    return Node(root.val)\\n\\ndef deserialize(root):\\n    if root is None:\\n        return None\\n    return deserialize(root.left) if root.left is not None else deserialize(root.right)\\n\\ndef binary_search_tree_serialize(root):\\n    serialize(root)\\n\\ndef binary_search_tree_deserialize(root):\\n    deserialize(root)\\n```\\n\\nIn this solution, we first define a Node class to represent each node in the binary search tree. The serialize function converts the root node into a string and returns it. The deserialize function tries to deserialize the string back to the root node. If the root is None, it returns None. If the root is not None, it recursively deserializes the left and right subtrees.\\n\\nThis solution has a time complexity of O(n) where n is the number of nodes in the binary search tree. This is because we need to traverse the tree once to convert it into a string and then decode it back to the tree.\\n\\nThis solution assumes that the input tree is a binary search tree. If the tree is not a binary search tree, the serialize and deserialize functions will raise an error.', token_ids=[16586, 4831, 909, 642, 272, 24441, 1846, 355, 34407, 5708, 284, 519, 8639, 419, 340, 9939, 296, 14912, 7607, 9768, 1619, 355, 7450, 322, 2678, 272, 24814, 766, 4884, 340, 296, 14912, 7607, 9768, 284, 8, 8, 54424, 419, 355, 8125, 6113, 327, 8, 8, 58676, 16328, 8, 7073, 33298, 327, 8, 3223, 1618, 5718, 6008, 7001, 1066, 287, 2352, 1078, 8, 485, 1066, 284, 7348, 406, 2352, 8, 485, 1066, 284, 6118, 406, 3573, 8, 485, 1066, 284, 5951, 406, 3573, 8, 8, 16244, 272, 43944, 290, 11588, 1078, 8, 3223, 920, 10067, 419, 3573, 327, 8, 485, 8718, 3573, 8, 481, 8718, 33298, 290, 11588, 284, 7348, 289, 8, 8, 16244, 272, 53183, 290, 11588, 1078, 8, 3223, 920, 10067, 419, 3573, 327, 8, 485, 8718, 3573, 8, 481, 8718, 272, 53183, 290, 11588, 284, 6118, 289, 920, 10067, 284, 6118, 419, 849, 3573, 3535, 272, 53183, 290, 11588, 284, 5951, 289, 8, 8, 16244, 14912, 318, 14428, 318, 14487, 318, 43944, 290, 11588, 1078, 8, 481, 43944, 290, 11588, 289, 8, 8, 16244, 14912, 318, 14428, 318, 14487, 318, 53183, 290, 11588, 1078, 8, 481, 53183, 290, 11588, 289, 8, 58676, 8, 8, 8188, 760, 6113, 287, 995, 2028, 10336, 355, 33298, 3386, 340, 4249, 2013, 10162, 347, 296, 14912, 7607, 9768, 284, 519, 272, 43944, 2933, 9939, 293, 296, 10067, 10162, 1619, 355, 7450, 322, 1715, 293, 766, 284, 519, 272, 53183, 2933, 272, 31344, 340, 272, 53183, 296, 7450, 4884, 340, 296, 10067, 10162, 284, 3347, 296, 10067, 419, 3573, 287, 766, 1715, 293, 3573, 284, 3347, 296, 10067, 419, 849, 3573, 287, 766, 34407, 429, 272, 53183, 293, 296, 5784, 322, 4755, 53604, 293, 284, 8, 8, 16586, 6113, 1346, 355, 1688, 4106, 2546, 312, 5211, 290, 846, 289, 2378, 3412, 419, 296, 1829, 312, 15384, 347, 296, 14912, 7607, 9768, 284, 1417, 419, 3743, 995, 3008, 340, 49104, 296, 9768, 8503, 340, 9939, 766, 1619, 355, 7450, 322, 2678, 272, 24814, 766, 4884, 340, 296, 9768, 284, 8, 8, 16586, 6113, 14269, 293, 477, 296, 6043, 9768, 419, 355, 14912, 7607, 9768, 284, 3347, 296, 9768, 419, 849, 355, 14912, 7607, 9768, 287, 296, 272, 43944, 322, 272, 53183, 6205, 1694, 6950, 812, 6969, 284, 2], cumulative_logprob=-20.9813777666239, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.915162, last_token_time=1716181722.915162, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.026236295700073242, finished_time=1716181727.8792691), lora_request=None),\n",
       " RequestOutput(request_id=40, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 523, 2040, 273, 966, 297, 271, 274, 773, 2701, 1335, 273, 3037, 1103, 303, 3254, 269, 1859, 271, 1335, 276, 3266, 271, 1011, 315, 286, 528, 871, 273, 872, 297, 421, 381, 554, 270, 8, 48979, 272, 1045, 2850, 327, 8, 2149, 533, 466, 270, 338, 1365, 373, 330, 354, 1335, 276, 269, 3266, 271, 528, 871, 274, 3486, 1077, 421, 381, 554, 441, 270, 1859, 271, 1335, 273, 1978, 297, 511, 331, 269, 1011, 315, 286, 523, 242, 202, 166, 302, 1492, 315, 1634, 1265, 281, 1578, 2471, 415, 270, 2, 1, 272, 8, 48979, 272, 3994, 327, 8, 3266, 275, 364, 271, 528, 871, 273, 462, 300, 523, 2040, 273, 966, 4460, 269, 1335, 273, 1978, 2005, 270, 3353, 438, 894, 276, 391, 310, 316, 351, 361, 438, 37843, 285, 278, 4066, 633, 275, 1175, 315, 274, 2196, 3799, 785, 500, 608, 316, 252, 201, 172, 285, 808, 1335, 275, 373, 501, 308, 270, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='了解です。以下のような質問を作成しました：「あなたは、XXXと呼ばれる言葉が、過去に一般的に使われていたことを知っていますか？」', token_ids=[2149, 533, 298, 270, 1411, 808, 1335, 273, 1978, 466, 252, 201, 167, 292, 894, 276, 269, 37843, 278, 1591, 895, 633, 275, 269, 1524, 274, 1175, 315, 274, 2196, 3799, 785, 500, 608, 316, 252, 201, 172, 285, 2], cumulative_logprob=-2.2516658379572547, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9155192, last_token_time=1716181722.9155192, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.0258791446685791, finished_time=1716181723.6944501), lora_request=None),\n",
       " RequestOutput(request_id=41, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 325, 684, 1710, 344, 269, 9872, 273, 1006, 544, 2045, 5192, 275, 1238, 580, 669, 517, 564, 286, 791, 1491, 375, 612, 269, 721, 335, 276, 292, 954, 570, 274, 465, 1244, 252, 201, 172, 285, 278, 1632, 282, 2626, 302, 292, 1222, 2611, 285, 278, 1632, 282, 7861, 488, 273, 5517, 628, 270, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='はい、その通りです。この文章では、リンゴをどのように扱ったのかがほとんど確認不可能な状態であるため、読者は「それが本当にそうなのか？」と軽い疑問を持ち、同時に「そうなのだろう」と軽い肯定をする可能性があります。', token_ids=[276, 282, 269, 313, 841, 298, 270, 325, 684, 1710, 344, 269, 9872, 273, 1006, 544, 2045, 5192, 275, 1238, 580, 669, 517, 564, 286, 791, 1491, 375, 612, 269, 721, 335, 276, 292, 954, 570, 274, 465, 1244, 252, 201, 172, 285, 278, 1632, 282, 2626, 273, 1121, 269, 1742, 274, 292, 1222, 2611, 285, 278, 1632, 282, 7861, 488, 273, 297, 564, 367, 554, 270, 2], cumulative_logprob=-2.2506297028467017, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9156017, last_token_time=1716181722.9156017, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.02579665184020996, finished_time=1716181724.0699387), lora_request=None),\n",
       " RequestOutput(request_id=42, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 518, 271, 2081, 276, 269, 283, 280, 280, 311, 310, 274, 8167, 277, 31873, 295, 5134, 826, 694, 370, 283, 295, 271, 7396, 1453, 1526, 953, 2518, 679, 270, 8, 8, 29424, 523, 274, 4614, 961, 297, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Română: În 2004, un organizației a fost implicată în care o infracțiune de 2 șoferi bulgari în Irak, în cadrul 2004.', token_ids=[17793, 802, 208, 175, 846, 209, 144, 327, 272, 208, 155, 846, 272, 283, 280, 280, 311, 287, 3676, 18345, 988, 213, 168, 8174, 1085, 355, 272, 20320, 3641, 26207, 209, 144, 272, 208, 187, 846, 6618, 13135, 347, 3464, 213, 168, 1085, 23766, 3989, 272, 283, 272, 213, 166, 5004, 27188, 272, 26644, 19078, 1085, 272, 208, 187, 846, 1086, 16453, 287, 272, 208, 187, 846, 2617, 52390, 10254, 272, 283, 280, 280, 311, 284, 2], cumulative_logprob=-4.721121585671575, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9156559, last_token_time=1716181722.9156559, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.025742530822753906, finished_time=1716181724.1871061), lora_request=None),\n",
       " RequestOutput(request_id=43, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 613, 271, 1335, 274, 1302, 1881, 272, 1335, 27305, 3991, 850, 367, 4468, 274, 4124, 320, 295, 728, 276, 391, 1498, 329, 272, 3021, 275, 326, 334, 358, 276, 438, 3021, 297, 331, 585, 275, 517, 1420, 298, 270, 285, 278, 330, 366, 2005, 270, 892, 271, 2959, 252, 201, 167, 15467, 306, 9755, 306, 53805, 272, 837, 252, 201, 167, 336, 280, 2314, 711, 617, 274, 1149, 320, 382, 394, 274, 3486, 1077, 270, 32641, 271, 11399, 13008, 274, 357, 8549, 10401, 306, 24553, 2229, 275, 269, 529, 367, 271, 985, 295, 1217, 1420, 286, 416, 273, 3617, 521, 278, 675, 479, 305, 10835, 271, 2229, 623, 3617, 587, 2494, 780, 445, 270, 367, 5216, 370, 1151, 273, 596, 291, 270, 2011, 282, 941, 271, 2245, 269, 32641, 271, 2298, 4475, 4535, 2229, 276, 269, 11534, 306, 16600, 3767, 2655, 278, 8884, 319, 1223, 271, 1372, 1136, 2469, 587, 2760, 501, 540, 270, 2229, 10833, 505, 278, 566, 2401, 537, 5024, 276, 623, 3617, 331, 370, 273, 330, 398, 9575, 588, 479, 297, 275, 269, 11534, 276, 313, 1202, 550, 416, 271, 1238, 275, 4935, 387, 1155, 269, 382, 511, 331, 3617, 14886, 276, 1478, 9575, 2382, 346, 270, 313, 368, 269, 11534, 276, 64809, 306, 35361, 22640, 22963, 288, 1114, 461, 853, 1542, 1257, 273, 596, 269, 313, 726, 275, 582, 271, 2755, 388, 573, 277, 2494, 780, 654, 278, 5575, 515, 270, 325, 875, 497, 277, 1511, 4095, 275, 20719, 269, 11534, 276, 2937, 728, 274, 35361, 22640, 278, 884, 3120, 301, 269, 2229, 573, 271, 1628, 278, 19094, 274, 3663, 361, 271, 1628, 286, 13545, 278, 442, 403, 605, 3943, 271, 11861, 952, 273, 381, 2023, 297, 270, 2627, 417, 252, 201, 167, 2015, 15069, 658, 32111, 51424, 8398, 2599, 271, 11534, 306, 16600, 3767, 2655, 252, 201, 149, 5002, 306, 3807, 55705, 252, 201, 150, 278, 313, 660, 295, 8884, 252, 201, 149, 5872, 306, 1489, 32393, 252, 201, 150, 276, 269, 11534, 271, 44604, 271, 367, 5216, 370, 1151, 2839, 273, 831, 503, 1178, 274, 32641, 271, 2229, 273, 623, 3617, 297, 275, 269, 2229, 274, 3678, 314, 416, 275, 6186, 1352, 530, 297, 270, 8710, 1680, 316, 811, 1051, 269, 1223, 271, 623, 3617, 276, 2229, 454, 277, 712, 3247, 301, 269, 4849, 573, 388, 573, 273, 295, 728, 274, 794, 320, 270, 2755, 276, 623, 3617, 275, 699, 342, 352, 375, 278, 574, 2062, 273, 596, 426, 270, 61365, 306, 35361, 22640, 3357, 348, 252, 201, 149, 23774, 306, 7309, 14947, 252, 201, 150, 278, 2892, 271, 3873, 1454, 275, 2229, 271, 827, 780, 273, 2494, 780, 305, 270, 35361, 22640, 275, 2229, 274, 1257, 304, 623, 3617, 271, 1453, 7709, 335, 11534, 274, 2755, 275, 2743, 1991, 273, 1167, 433, 269, 11534, 276, 364, 278, 1765, 1180, 777, 2599, 335, 271, 8884, 275, 295, 728, 273, 794, 3543, 678, 316, 275, 2229, 670, 2240, 1130, 1356, 354, 278, 3873, 1914, 297, 270, 35361, 22640, 3357, 348, 275, 295, 728, 884, 3120, 295, 273, 3748, 269, 21509, 5700, 1454, 13487, 5692, 290, 17599, 306, 13023, 59455, 289, 275, 518, 271, 1200, 273, 1306, 789, 390, 270, 8256, 573, 271, 30230, 252, 201, 149, 5872, 306, 49781, 252, 201, 150, 275, 12047, 1015, 271, 399, 385, 273, 1149, 8654, 269, 35361, 22640, 275, 3544, 479, 273, 1310, 304, 295, 728, 273, 381, 2023, 600, 11534, 276, 30230, 273, 5232, 297, 270, 35361, 22640, 276, 11534, 274, 269, 2229, 271, 403, 274, 330, 294, 2755, 275, 1559, 502, 1930, 315, 375, 316, 273, 580, 669, 6833, 680, 687, 297, 270, 2128, 304, 269, 11534, 276, 341, 302, 1716, 771, 292, 41959, 20472, 809, 273, 655, 308, 270, 50198, 273, 8626, 433, 269, 4608, 271, 3132, 3751, 275, 4194, 602, 273, 1058, 655, 291, 239, 141, 179, 8, 1302, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='映画「ドッグ・デイ・アフタヌーン」において、糖尿病性ショックに陥った人質は存在しません。この映画では、銀行強盗が人質を取るシーンが描かれていますが、その中で糖尿病性ショックに陥った人物は記載されていません。', token_ids=[892, 292, 15467, 306, 9755, 306, 53805, 285, 1073, 269, 2965, 3991, 850, 367, 4468, 274, 4124, 320, 295, 728, 276, 847, 3308, 270, 325, 892, 344, 269, 2229, 623, 3617, 275, 295, 728, 273, 794, 291, 2195, 275, 1326, 3200, 1173, 269, 313, 352, 277, 2965, 3991, 850, 367, 4468, 274, 4124, 320, 2469, 276, 514, 1462, 908, 823, 270, 2], cumulative_logprob=-1.1959573264166323, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9157069, last_token_time=1716181722.9157069, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.025691509246826172, finished_time=1716181723.9874165), lora_request=None),\n",
       " RequestOutput(request_id=44, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 3191, 447, 1644, 275, 23782, 273, 721, 464, 536, 953, 297, 1335, 274, 1302, 291, 1721, 273, 2880, 2026, 373, 540, 270, 337, 1102, 662, 22141, 271, 2881, 561, 2055, 278, 36989, 6454, 273, 2881, 561, 1128, 271, 274, 512, 271, 662, 2420, 275, 421, 381, 414, 612, 269, 7789, 2120, 286, 662, 278, 4224, 282, 1837, 662, 275, 1238, 1016, 641, 1907, 270, 4034, 271, 3728, 315, 777, 2881, 650, 662, 3781, 2115, 778, 926, 1003, 270, 285, 319, 897, 446, 395, 282, 1335, 273, 373, 6404, 3863, 270, 1102, 662, 3202, 3216, 1633, 270, 23337, 1102, 662, 7150, 271, 3037, 271, 682, 331, 269, 1859, 271, 20499, 273, 47643, 297, 271, 274, 773, 2701, 7439, 275, 2069, 2143, 22141, 275, 1310, 908, 308, 270, 2482, 271, 5595, 277, 3455, 315, 274, 3216, 445, 23337, 1102, 662, 277, 1797, 269, 22141, 2269, 304, 1102, 662, 445, 544, 2495, 308, 270, 2482, 271, 3216, 270, 23337, 656, 271, 1904, 274, 1052, 294, 269, 22141, 273, 462, 320, 1102, 662, 271, 1865, 282, 731, 3928, 1227, 270, 285, 8, 1302, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='以下のような質問が考えられます：\\n\\n1. 録音ホーンの振動板とカッティング機構を振動させるのに多くの音エネルギーが必要だった理由は何ですか？\\n2. この文章で言及されている「繊細な音と細かい倍音」とは具体的にどのような音を指していますか？\\n3. 両方の機械的共振による音響上の限界があったと述べられていますが、これらの共振は具体的に何を指していますか？\\n4. アコースティック録音セッションでテープが巻かれたホーンが示されている例はどのようなものですか？\\n5. 現代の機器で電気的に再生されたアコースティック録音でさえ、ホーンを通して録音されたように聞こえます。これは何故ですか？\\n6. アコースティック時代の終わりに向けて、ホーンを使った録音の素晴らしい例がたくさんありました。具体的にどのような例がありますか？', token_ids=[1411, 808, 1335, 275, 373, 501, 308, 252, 201, 167, 8, 8, 279, 284, 272, 1102, 662, 22141, 271, 2881, 561, 2055, 278, 36989, 6454, 273, 2881, 561, 1128, 271, 274, 512, 271, 662, 2420, 275, 421, 381, 414, 842, 276, 391, 1498, 252, 201, 172, 8, 283, 284, 631, 684, 1710, 277, 393, 3212, 654, 292, 7789, 2120, 286, 662, 278, 4224, 282, 1837, 662, 285, 278, 276, 1295, 389, 315, 274, 1006, 531, 662, 273, 819, 552, 316, 252, 201, 172, 8, 299, 284, 272, 4034, 271, 3728, 315, 777, 2881, 650, 662, 3781, 2115, 778, 926, 1003, 278, 2542, 1380, 1173, 269, 1859, 271, 777, 2881, 276, 1295, 389, 315, 274, 391, 273, 819, 552, 316, 252, 201, 172, 8, 311, 284, 272, 23337, 1102, 662, 7150, 277, 7439, 275, 2069, 2143, 22141, 275, 1310, 654, 731, 276, 1006, 2884, 1498, 252, 201, 172, 8, 307, 284, 14214, 271, 5595, 277, 3455, 315, 274, 3216, 445, 23337, 1102, 662, 277, 1797, 269, 22141, 2269, 304, 1102, 662, 445, 544, 2495, 308, 270, 581, 3109, 1498, 252, 201, 172, 8, 328, 284, 272, 23337, 656, 271, 1904, 274, 1052, 294, 269, 22141, 273, 462, 320, 1102, 662, 271, 1865, 282, 731, 3928, 1227, 270, 1295, 389, 315, 274, 1006, 531, 731, 554, 316, 252, 201, 172, 2], cumulative_logprob=-4.115940184494029, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9158292, last_token_time=1716181722.9158292, first_scheduled_time=1716181722.9413984, first_token_time=1716181723.0627258, time_in_queue=0.02556920051574707, finished_time=1716181726.0153086), lora_request=None),\n",
       " RequestOutput(request_id=45, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 613, 271, 892, 271, 21515, 953, 297, 1335, 273, 447, 603, 415, 270, 11858, 18830, 272, 271, 2102, 538, 286, 3306, 3108, 375, 15230, 8970, 272, 26887, 2605, 380, 31582, 272, 56861, 18788, 289, 272, 276, 269, 2543, 277, 8060, 380, 7345, 272, 23729, 2430, 289, 272, 278, 3306, 7101, 446, 4589, 608, 270, 1539, 278, 3306, 1662, 297, 529, 367, 271, 675, 479, 274, 2382, 423, 15230, 8970, 276, 269, 4593, 959, 271, 844, 375, 8916, 1414, 283, 280, 310, 1221, 394, 273, 518, 274, 1167, 7144, 270, 22512, 938, 53621, 271, 1183, 375, 40624, 306, 8916, 252, 201, 149, 10546, 306, 38043, 252, 201, 150, 276, 269, 9083, 277, 42889, 252, 201, 149, 27501, 23375, 306, 46538, 252, 201, 150, 278, 1300, 269, 507, 1698, 10005, 629, 273, 1901, 3013, 305, 270, 40624, 276, 42889, 278, 2472, 301, 269, 518, 458, 276, 660, 503, 765, 270, 42889, 276, 2031, 271, 12175, 274, 27792, 3840, 269, 1223, 276, 13208, 273, 777, 274, 1612, 1323, 495, 270, 1784, 315, 274, 1223, 276, 839, 301, 269, 1223, 271, 714, 273, 23029, 308, 270, 428, 310, 275, 528, 1685, 269, 8916, 434, 276, 450, 5593, 2770, 1247, 269, 42889, 276, 5202, 335, 275, 710, 3735, 320, 1153, 282, 6918, 2167, 273, 1543, 269, 779, 1000, 379, 415, 270, 579, 269, 5582, 1984, 286, 42889, 275, 21152, 1252, 1084, 395, 9734, 278, 373, 426, 612, 269, 714, 1281, 10905, 2379, 7419, 269, 279, 280, 575, 495, 361, 8707, 275, 1375, 1966, 339, 269, 1059, 274, 6054, 6729, 275, 3508, 426, 2012, 270, 40624, 275, 518, 271, 2500, 2543, 271, 5114, 356, 1585, 297, 10620, 269, 42889, 276, 40624, 278, 271, 624, 274, 13159, 301, 655, 5787, 644, 269, 1742, 274, 40624, 278, 518, 271, 944, 1164, 273, 996, 282, 655, 308, 270, 42889, 275, 13240, 2079, 273, 969, 346, 10309, 9626, 269, 40624, 356, 276, 269, 42889, 271, 1632, 12631, 273, 622, 360, 1482, 364, 275, 391, 273, 305, 271, 316, 373, 1158, 823, 270, 40624, 275, 5509, 399, 385, 274, 2595, 1005, 278, 1921, 426, 1054, 269, 382, 511, 331, 252, 201, 149, 22597, 6729, 13480, 13919, 252, 201, 150, 443, 676, 269, 42889, 276, 391, 271, 2792, 888, 281, 1310, 3308, 518, 271, 6329, 1272, 269, 1863, 368, 5220, 1272, 270, 40624, 275, 1061, 1146, 305, 1318, 4589, 282, 457, 277, 269, 40624, 276, 518, 275, 746, 5147, 549, 2558, 278, 1736, 303, 270, 817, 276, 1784, 315, 274, 269, 521, 518, 273, 601, 1196, 6061, 1736, 269, 3306, 2026, 373, 540, 270, 40624, 276, 779, 2866, 269, 839, 624, 273, 7872, 1896, 1234, 533, 273, 24879, 619, 278, 1002, 863, 297, 270, 579, 269, 40624, 331, 1164, 271, 1493, 752, 713, 374, 273, 2361, 297, 738, 475, 443, 4333, 269, 42889, 275, 434, 278, 1647, 357, 1164, 1528, 273, 1371, 1005, 813, 1943, 316, 1247, 269, 565, 8496, 277, 1223, 3460, 2715, 1089, 275, 3508, 308, 270, 42889, 275, 40624, 271, 3084, 451, 278, 476, 742, 252, 201, 149, 364, 275, 746, 1542, 278, 345, 3930, 274, 451, 282, 2736, 252, 201, 150, 273, 475, 404, 304, 269, 40624, 276, 434, 273, 1443, 1946, 675, 479, 273, 1630, 578, 274, 9493, 291, 270, 8, 1302, 252, 201, 167, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='1. 映画「ギャビン・ダマト」の主人公であるギャビン・ダマトは、どのような仕事をしていますか？\\n2. ローズ家の話について、ギャビンはどのような情報を顧客に伝えましたか？\\n3. オリバーとバーバラが結婚する前に、二人はどのような関係でしたか？\\n4. ローズ家がより裕福になるにつれて、家族に亀裂が生じた理由は何ですか？\\n5. オリバーが心臓発作を起こしたと考えていた時、実際には何が起きていましたか？\\n6. バーバラはオリバーの死を受け入れる前に、どのような決意を固めていましたか？\\n7. 法廷で二人の間に緊張が生じた理由は何ですか？\\n8. バーバラがオリバーの遺書とされるものを利用して、どのような決意を固めましたか？', token_ids=[279, 284, 9460, 292, 15230, 8970, 306, 26887, 2605, 285, 271, 1973, 783, 375, 15230, 8970, 306, 26887, 2605, 276, 269, 1006, 531, 504, 273, 552, 316, 252, 201, 172, 8, 283, 284, 272, 8916, 1414, 394, 446, 269, 15230, 8970, 276, 1006, 531, 585, 273, 4593, 959, 274, 1167, 10286, 252, 201, 172, 8, 299, 284, 272, 40624, 278, 42889, 275, 839, 297, 351, 274, 269, 1223, 276, 1006, 531, 567, 456, 316, 252, 201, 172, 8, 311, 284, 272, 8916, 434, 275, 450, 5593, 2770, 495, 9626, 269, 1059, 274, 6054, 6729, 275, 3508, 303, 842, 276, 391, 1498, 252, 201, 172, 8, 307, 284, 272, 40624, 275, 5509, 399, 385, 273, 1149, 305, 278, 373, 718, 353, 269, 382, 511, 331, 391, 275, 1186, 1750, 316, 252, 201, 172, 8, 328, 284, 272, 42889, 276, 40624, 271, 746, 273, 2866, 291, 351, 274, 269, 1006, 531, 675, 479, 273, 7130, 1750, 316, 252, 201, 172, 8, 336, 284, 272, 565, 8496, 277, 1223, 3460, 2715, 1089, 275, 3508, 303, 842, 276, 391, 1498, 252, 201, 172, 8, 332, 284, 272, 42889, 275, 40624, 271, 3084, 451, 278, 476, 742, 273, 475, 404, 304, 269, 1006, 531, 675, 479, 273, 7130, 10286, 252, 201, 172, 2], cumulative_logprob=-20.721158936469536, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9158864, last_token_time=1716181722.9158864, first_scheduled_time=1716181723.0634704, first_token_time=1716181723.1618643, time_in_queue=0.1475839614868164, finished_time=1716181725.8730261), lora_request=None),\n",
       " RequestOutput(request_id=46, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 12311, 271, 4239, 278, 379, 366, 273, 2037, 304, 269, 330, 366, 277, 1045, 2850, 415, 270, 2304, 5362, 275, 1252, 501, 308, 275, 269, 313, 1302, 276, 36684, 2085, 272, 298, 270, 3021, 275, 36684, 2665, 272, 274, 17369, 1317, 269, 2037, 445, 1335, 273, 7799, 778, 274, 1673, 297, 421, 381, 554, 270, 325, 12311, 331, 2423, 269, 279, 272, 1574, 607, 523, 269, 1431, 292, 18629, 607, 523, 285, 273, 313, 733, 479, 523, 274, 8935, 291, 1392, 275, 2778, 2051, 380, 3353, 438, 777, 396, 285, 288, 292, 2370, 282, 285, 274, 1673, 289, 270, 1252, 630, 1335, 271, 837, 273, 272, 279, 272, 412, 272, 283, 272, 607, 523, 269, 1431, 18629, 272, 10498, 272, 8669, 273, 1874, 294, 1673, 4096, 1150, 270, 7583, 2085, 272, 278, 7583, 2665, 272, 275, 749, 833, 273, 5362, 291, 564, 367, 275, 507, 3322, 276, 2449, 270, 2202, 1335, 446, 276, 269, 749, 833, 273, 5362, 1794, 271, 1420, 274, 588, 479, 445, 3021, 275, 7583, 2665, 272, 375, 421, 381, 554, 270, 2202, 1064, 575, 331, 269, 4391, 1565, 315, 274, 3232, 1698, 286, 17953, 269, 6535, 286, 17953, 269, 3396, 13937, 272, 17953, 275, 2778, 8614, 294, 276, 2449, 270, 1335, 457, 277, 382, 1565, 271, 2469, 271, 1132, 302, 1175, 315, 286, 1132, 380, 731, 272, 23359, 22561, 269, 5872, 272, 9262, 289, 272, 273, 872, 4096, 1150, 270, 1673, 305, 1335, 273, 447, 603, 297, 511, 274, 269, 507, 2728, 302, 8669, 273, 1910, 398, 1860, 2005, 270, 325, 12311, 276, 269, 607, 1763, 286, 3136, 269, 1431, 849, 272, 302, 16485, 272, 339, 273, 2359, 2294, 914, 274, 533, 675, 1517, 270, 2923, 274, 269, 607, 523, 271, 401, 411, 367, 273, 3106, 6610, 2005, 270, 1335, 331, 1493, 752, 272, 279, 307, 272, 607, 523, 269, 1867, 272, 299, 280, 272, 607, 523, 273, 2096, 291, 421, 381, 554, 270, 1335, 331, 269, 2037, 445, 1335, 278, 1493, 752, 272, 336, 280, 604, 272, 873, 3030, 297, 607, 523, 275, 2778, 1408, 421, 381, 554, 270, 1335, 273, 451, 346, 511, 331, 269, 2037, 445, 684, 5427, 607, 523, 273, 2171, 297, 421, 381, 554, 270, 1335, 331, 749, 833, 273, 272, 279, 272, 15811, 2096, 291, 421, 381, 554, 270, 7583, 2085, 272, 278, 7583, 2665, 272, 271, 10051, 275, 507, 375, 785, 580, 669, 2005, 270, 2202, 1335, 344, 269, 26083, 2085, 272, 278, 7583, 2665, 272, 276, 272, 279, 272, 362, 435, 872, 297, 421, 381, 940, 269, 26083, 2085, 272, 276, 7583, 2665, 272, 905, 351, 274, 330, 550, 297, 421, 381, 554, 270, 793, 533, 276, 2209, 2016, 269, 4619, 271, 272, 279, 272, 15811, 273, 451, 346, 421, 381, 554, 270, 8, 8, 684, 5427, 607, 523, 272, 10231, 270, 8, 1335, 272, 295, 4225, 272, 271, 4199, 276, 269, 906, 857, 356, 10713, 4748, 273, 872, 390, 612, 269, 295, 6302, 272, 271, 4199, 905, 914, 274, 12387, 277, 10231, 1828, 270, 8, 1302, 272, 295, 2085, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='質問: 人 X のケーキは、材料としてアップルソースを使用していないため、人 Y のケーキよりも常にふわふわで乾燥していました。\\n答え: 人Y', token_ids=[1335, 327, 272, 295, 4225, 272, 271, 4199, 276, 269, 906, 857, 356, 10713, 4748, 273, 872, 301, 1201, 612, 269, 295, 6302, 272, 271, 4199, 905, 914, 274, 12387, 277, 2488, 3441, 1828, 270, 8, 1302, 327, 272, 295, 2665, 2], cumulative_logprob=-0.6945153994411157, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9353034, last_token_time=1716181722.9353034, first_scheduled_time=1716181723.0634704, first_token_time=1716181723.1618643, time_in_queue=0.12816691398620605, finished_time=1716181723.7253742), lora_request=None),\n",
       " RequestOutput(request_id=47, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 14875, 605, 1589, 3800, 273, 451, 8857, 270, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='ロサンゼルスへの旅行プランは、以下のようになります。\\n\\n1. 出発日：20XX年X月X日\\n2. 目的地：ロサンゼルス\\n3. 宿泊先：ホテル（XXX）\\n4. 移動手段：飛行機（XXX）\\n5. 観光スポット：ハリウッド、サンタモニカ、グリフィス天文台、ユニバーサルスタジオ、ディズニーランド、ナッツベリーファーム、ロサンゼルスのダウンタウン、グリフィスパーク、ロサンゼルスのビーチ、サンタモニカのビーチ、ハリウッドのウォーク・オブ・フェーム、ロサンゼルスのミュージアム、ロサンゼルスの動物園、ロサンゼルスの植物園、ロサンゼルスの美術館、ロサンゼルスの動物園、ロサンゼルスの水族館、ロサンゼルスのディズニーランド、ロサンゼルスのユニバーサルスタジオ、ロサンゼルスのナッツベリーファーム、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン、ロサンゼルスのダウンタウン', token_ids=[14875, 605, 1589, 3800, 276, 269, 1411, 754, 1416, 270, 8, 8, 279, 284, 272, 330, 399, 324, 252, 201, 167, 283, 280, 21991, 310, 2085, 343, 2085, 324, 8, 283, 284, 272, 1286, 524, 252, 201, 167, 14875, 8, 299, 284, 272, 1557, 2748, 455, 252, 201, 167, 1749, 252, 201, 149, 37843, 252, 201, 150, 8, 311, 284, 272, 1878, 370, 962, 252, 201, 167, 3943, 252, 201, 149, 37843, 252, 201, 150, 8, 307, 284, 272, 1806, 4912, 252, 201, 167, 11593, 269, 61918, 269, 61761, 14969, 870, 269, 22915, 5421, 269, 18244, 269, 15924, 12644, 14100, 269, 14875, 271, 19508, 269, 61761, 7141, 269, 14875, 271, 7811, 269, 61918, 271, 7811, 269, 11593, 271, 17235, 306, 7655, 306, 40362, 3605, 269, 14875, 271, 14344, 269, 14875, 271, 10192, 269, 14875, 271, 3075, 1640, 269, 14875, 271, 5171, 269, 14875, 271, 10192, 269, 14875, 271, 12087, 269, 14875, 271, 18244, 269, 14875, 271, 22915, 5421, 269, 14875, 271, 15924, 12644, 14100, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508, 269, 14875, 271, 19508], cumulative_logprob=-10.03965461770833, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9354253, last_token_time=1716181722.9354253, first_scheduled_time=1716181723.0634704, first_token_time=1716181723.1618643, time_in_queue=0.12804508209228516, finished_time=1716181729.5422204), lora_request=None),\n",
       " RequestOutput(request_id=48, prompt=None, prompt_token_ids=[272, 1411, 276, 269, 12311, 273, 680, 530, 297, 3994, 278, 269, 684, 5427, 271, 357, 379, 366, 271, 3754, 298, 270, 381, 2023, 273, 950, 1219, 274, 4074, 354, 1045, 2850, 273, 1530, 3314, 270, 8, 8, 48979, 272, 3994, 327, 8, 1570, 282, 1175, 1791, 271, 1335, 272, 59030, 3663, 276, 391, 5255, 274, 1040, 316, 329, 8, 1302, 252, 201, 167, 8, 8, 48979, 272, 1045, 2850, 327, 8], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='ヒースロー空港はイギリスのサウス・ヨークシャー郡に位置しています。', token_ids=[59030, 3663, 276, 3681, 271, 27806, 306, 61723, 5255, 274, 2197, 552, 270, 2], cumulative_logprob=-0.8034765636981547, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716181722.9354684, last_token_time=1716181722.9354684, first_scheduled_time=1716181723.0634704, first_token_time=1716181723.1618643, time_in_queue=0.12800192832946777, finished_time=1716181723.3397918), lora_request=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
