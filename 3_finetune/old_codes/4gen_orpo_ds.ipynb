{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name=\"kanhatakeyama/0516tanuki_lr5e5_epoch1\"\n",
    "#model_name=\"../X_merge/merged_models/0517\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                            #quantization_config=bnb_config, \n",
    "                                            device_map=\"auto\",\n",
    "                                            torch_dtype=torch.bfloat16,\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_adapter(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipeline('text-generation',model=model,tokenizer=tokenizer, \n",
    "              max_new_tokens=512, \n",
    "              repetition_penalty=1.2,\n",
    "              temperature=0.6,\n",
    "              #repetition_penalty=1.,\n",
    "              #temperature=0.1,\n",
    "              #top_p=1.0,\n",
    "              #top_k=0.\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "question_template=\"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n\"\n",
    "answer_template=\"\\n\\n### 応答:\\n\"\n",
    "answer_template=\"\\n\\n### 応答:\\n\"\n",
    "\n",
    "def gen_prompt(q):\n",
    "    return f\"{question_template}{q}{answer_template}\"\n",
    "\n",
    "\n",
    "def dump(res_list):\n",
    "    df=pd.DataFrame(res_list)\n",
    "    df.to_csv(\"data/raw_ans.csv\",index=False)\n",
    "\n",
    "#dump(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\n",
    "\"計算してください 1+1はいくつですか｡\",\n",
    "\"1+2+3-4=\",\n",
    "\"ドラえもんの友達はだれですか?\",\n",
    "\"レイリー散乱とはなんですか\",\n",
    "\"hello!\",\n",
    "\"今の天気は晴れで25℃、明日の天気は雨23℃です｡この結果をjsonで出力してください｡ \",\n",
    "\"iphoneの評価は4で感想は高すぎ, androidの評価は5でgoogle最高!, というレビューをyamlで出力してください｡\",\n",
    "\"たぬきに純粋理性批判は理解できますか?\",\n",
    " \"日本の首相は?\",\n",
    "\"東京科学大学の学長は?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list=[]\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    inp=gen_prompt(question)\n",
    "    print(\"--------------------\")\n",
    "    print(question)\n",
    "    res=pipe(inp,)[0][\"generated_text\"][len(inp):]\n",
    "    print(res)\n",
    "\n",
    "    d={\n",
    "        \"q\":question,\n",
    "        \"model_a\":res,\n",
    "        \"ref_a\":\"\",\n",
    "        \"database\":\"original\",\n",
    "    }\n",
    "    res_list.append(d)\n",
    "\n",
    "\n",
    "dump(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "chat_path=\"bench_data/0514llmchat.csv\"\n",
    "df=pd.read_csv(chat_path)\n",
    "df=df[df[\"question\"].notnull()]\n",
    "records=df.to_dict(orient=\"records\")\n",
    "\n",
    "for record in tqdm(records):\n",
    "    question=record[\"question\"]\n",
    "    inp=gen_prompt(question)\n",
    "    print(\"--------------------\")\n",
    "    print(question)\n",
    "    res=pipe(inp,)[0][\"generated_text\"][len(inp):]\n",
    "    print(res)\n",
    "\n",
    "    d={\n",
    "        \"q\":question,\n",
    "        \"model_a\":res,\n",
    "        \"ref_a\":record[\"answer\"],\n",
    "        \"database\":\"llmchat\",\n",
    "    }\n",
    "\n",
    "    res_list.append(d)\n",
    "\n",
    "\n",
    "dump(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#minnade\n",
    "m_ds=load_dataset(\"minnade/chat-daily\",split=\"train\")\n",
    "\n",
    "id_to_content={}\n",
    "for record in m_ds:\n",
    "    id_to_content[record[\"id\"]]=record[\"body\"]\n",
    "\n",
    "done_questions=[]\n",
    "for record in tqdm(m_ds):\n",
    "    if record[\"role\"]==\"assistant\":\n",
    "        q=id_to_content[record[\"parent_id\"]]\n",
    "        a=record[\"body\"]\n",
    "        if a is None:\n",
    "            continue\n",
    "        if len(a)<4:\n",
    "            continue\n",
    "        #questions.append((q,a))\n",
    "        if q in done_questions:\n",
    "            continue\n",
    "        done_questions.append(q)\n",
    "        inp=gen_prompt(q)\n",
    "        print(\"--------------------\")\n",
    "        print(q)\n",
    "        res=pipe(inp,)[0][\"generated_text\"][len(inp):]\n",
    "        print(res)\n",
    "\n",
    "\n",
    "        d={\n",
    "                \"q\":q,\n",
    "                \"model_a\":res,\n",
    "                \"ref_a\":a,\n",
    "                \"database\":\"minnnade\",\n",
    "            }\n",
    "\n",
    "    res_list.append(d)\n",
    "\n",
    "\n",
    "dump(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elyza\n",
    "\n",
    "m_ds=load_dataset(\"elyza/ELYZA-tasks-100\",split=\"test\")\n",
    "\n",
    "\n",
    "for record in tqdm(m_ds):\n",
    "    q=record[\"input\"]\n",
    "    #questions.append((q,a))\n",
    "    inp=gen_prompt(q)\n",
    "    print(\"--------------------\")\n",
    "    print(question)\n",
    "    res=pipe(inp,)[0][\"generated_text\"][len(inp):]\n",
    "    print(res)\n",
    "\n",
    "\n",
    "    d={\n",
    "            \"q\":q,\n",
    "            \"model_a\":res,\n",
    "            \"ref_a\":record[\"output\"],\n",
    "            \"database\":\"elyza\",\n",
    "        }\n",
    "\n",
    "    res_list.append(d)\n",
    "\n",
    "dump(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
