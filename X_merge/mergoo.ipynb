{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mergoo.compose_experts import ComposeExperts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    \"model_type\": \"llama\",\n",
    "    \"num_experts_per_tok\": 2,\n",
    "    \"experts\":[\n",
    "        {\n",
    "            \"expert_name\" : \"base_expert\",\n",
    "            \"model_id\" : \"../../llm/models/hf/old/2jaA\"\n",
    "        },\n",
    "        {\n",
    "            \"expert_name\" : \"expert_1\",\n",
    "            \"model_id\" : \"../../llm/models/hf/old/2jaA\"\n",
    "        },\n",
    "        {\n",
    "            \"expert_name\" : \"expert_2\",\n",
    "            \"model_id\" : \"../../llm/models/hf/old/1code\"\n",
    "        }\n",
    "    ],\n",
    "    \"router_layers\":[\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"merged_models/mergoo_llama_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expertmerger = ComposeExperts(config, torch_dtype=torch.float16)\n",
    "#expertmerger.compose()\n",
    "#expertmerger.save_checkpoint(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the composed checkkpoint\n",
    "import torch\n",
    "from mergoo.models.modeling_llama import LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16,\n",
    ")# 'gate' / router layers are untrained hence loaded warning would appeare for them\n",
    "\n",
    "\n",
    "\n",
    "# train only router (gating) layers\n",
    "n_weights, n_router_weights  = 0,0\n",
    "for name, weight in model.named_parameters():\n",
    "    if \"gate\" not in name:\n",
    "        weight.requires_grad_(False)\n",
    "        n_router_weights += 1\n",
    "    n_weights += 1\n",
    "n_weights, n_router_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
